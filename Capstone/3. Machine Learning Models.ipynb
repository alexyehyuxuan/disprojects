{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T22:01:43.330468Z",
     "start_time": "2021-01-27T22:01:43.316084Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import regex as re\n",
    "import joblib\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_roc_curve, roc_auc_score, mean_squared_error\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "import en_core_web_sm\n",
    "from spacy import vocab\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T22:01:44.225275Z",
     "start_time": "2021-01-27T22:01:44.219774Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T22:01:47.032569Z",
     "start_time": "2021-01-27T22:01:45.340599Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>yta</th>\n",
       "      <th>nta</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>nltk_lem</th>\n",
       "      <th>nltk_pos</th>\n",
       "      <th>spacy_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jbswil</td>\n",
       "      <td>Thanks for this. When I was getting gaslit I c...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>thanks getting gaslit came couple times got lo...</td>\n",
       "      <td>thanks getting gaslit came couple time got lot...</td>\n",
       "      <td>thanks get gaslit come couple time get lot sta...</td>\n",
       "      <td>thank get gaslit come couple time get lot stay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k4owfz</td>\n",
       "      <td>does the 'no covid posts' rule extend to the c...</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>covid posts rule extend comments seen posts to...</td>\n",
       "      <td>covid post rule extend comment seen post top c...</td>\n",
       "      <td>covid post rule extend comment see post top co...</td>\n",
       "      <td>covid post rule extend comment see post commen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k4owfz</td>\n",
       "      <td>Where do mods draw the line as far as the \"acc...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mods draw line far accept judgment rule get tr...</td>\n",
       "      <td>mod draw line far accept judgment rule get tri...</td>\n",
       "      <td>mod draw line far accept judgment rule get tri...</td>\n",
       "      <td>mod draw line far accept judgment rule tricky ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k4owfz</td>\n",
       "      <td>Does anyone ever ask AITA for cutting off fami...</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>anyone ever ask cutting family results verdict...</td>\n",
       "      <td>anyone ever ask cutting family result verdict ...</td>\n",
       "      <td>anyone ever ask cut family result verdict seem...</td>\n",
       "      <td>ask cut family result verdict like general rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k4owfz</td>\n",
       "      <td>AITA has reduced to recycling the same comment...</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>reduced recycling comments get upvotes well wr...</td>\n",
       "      <td>reduced recycling comment get upvotes well wri...</td>\n",
       "      <td>reduce recycle comment get upvotes well write ...</td>\n",
       "      <td>reduce recycling comment upvote write comment ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id                                       comment_text  comment_score  \\\n",
       "0  jbswil  Thanks for this. When I was getting gaslit I c...              2   \n",
       "1  k4owfz  does the 'no covid posts' rule extend to the c...             38   \n",
       "2  k4owfz  Where do mods draw the line as far as the \"acc...             15   \n",
       "3  k4owfz  Does anyone ever ask AITA for cutting off fami...             28   \n",
       "4  k4owfz  AITA has reduced to recycling the same comment...             32   \n",
       "\n",
       "   yta  nta                                       cleaned_text  \\\n",
       "0    1    0  thanks getting gaslit came couple times got lo...   \n",
       "1    1    0  covid posts rule extend comments seen posts to...   \n",
       "2    1    0  mods draw line far accept judgment rule get tr...   \n",
       "3    1    0  anyone ever ask cutting family results verdict...   \n",
       "4    1    0  reduced recycling comments get upvotes well wr...   \n",
       "\n",
       "                                            nltk_lem  \\\n",
       "0  thanks getting gaslit came couple time got lot...   \n",
       "1  covid post rule extend comment seen post top c...   \n",
       "2  mod draw line far accept judgment rule get tri...   \n",
       "3  anyone ever ask cutting family result verdict ...   \n",
       "4  reduced recycling comment get upvotes well wri...   \n",
       "\n",
       "                                            nltk_pos  \\\n",
       "0  thanks get gaslit come couple time get lot sta...   \n",
       "1  covid post rule extend comment see post top co...   \n",
       "2  mod draw line far accept judgment rule get tri...   \n",
       "3  anyone ever ask cut family result verdict seem...   \n",
       "4  reduce recycle comment get upvotes well write ...   \n",
       "\n",
       "                                           spacy_lem  \n",
       "0  thank get gaslit come couple time get lot stay...  \n",
       "1  covid post rule extend comment see post commen...  \n",
       "2  mod draw line far accept judgment rule tricky ...  \n",
       "3  ask cut family result verdict like general rig...  \n",
       "4  reduce recycling comment upvote write comment ...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in the dataset\n",
    "final = pd.read_csv('datasets/final.csv')\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T22:01:47.035742Z",
     "start_time": "2021-01-27T22:01:47.033736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178015, 9)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T22:01:47.375405Z",
     "start_time": "2021-01-27T22:01:47.301349Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_id          False\n",
       "comment_text     False\n",
       "comment_score    False\n",
       "yta              False\n",
       "nta              False\n",
       "cleaned_text      True\n",
       "nltk_lem          True\n",
       "nltk_pos          True\n",
       "spacy_lem         True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because some of these comments were just 'YTA' or 'NTA' it created blank fields when the stop words filtered them out and subsequently became null fields when imported. Since these don't have any value in a language model, I will be dropping these data entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T22:01:50.629862Z",
     "start_time": "2021-01-27T22:01:50.518634Z"
    }
   },
   "outputs": [],
   "source": [
    "final.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next section, I generated several combinations of machine learning models using 4 of the different lemmatization formats created in the first part of this project. \n",
    "\n",
    "Texts\n",
    "1. cleaned_text\n",
    "2. nltk_lem\n",
    "3. nltk_pos\n",
    "4. spacy_lem\n",
    "\n",
    "\n",
    "Vectorizers\n",
    "1. CountVectorizer\n",
    "2. TfidfVectorizer \n",
    "\n",
    "Sampled\n",
    "1. Smote \n",
    "\n",
    "Classified through Model\n",
    "1. MultinomialNB\n",
    "2. LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T22:01:54.248198Z",
     "start_time": "2021-01-27T22:01:54.237160Z"
    }
   },
   "outputs": [],
   "source": [
    "#Assigning stopwords\n",
    "stop_words = set(stopwords.words('english'))  \n",
    "special_stops = {'YTA', 'yta', 'NTA', 'nta', 'ESH', 'esh', 'NAH', 'nah', 'wibta', 'aita'}\n",
    "stop_words = stop_words.union(special_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T22:01:54.516715Z",
     "start_time": "2021-01-27T22:01:54.510785Z"
    }
   },
   "outputs": [],
   "source": [
    "X = final['cleaned_text']\n",
    "y = final['yta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T22:01:56.526146Z",
     "start_time": "2021-01-27T22:01:56.436230Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                   test_size = 0.33,\n",
    "                                                   random_state = 42,\n",
    "                                                   stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T22:01:58.639062Z",
     "start_time": "2021-01-27T22:01:58.626783Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.771874\n",
       "1    0.228126\n",
       "Name: yta, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check Baseline accuracy\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline accuracy to beat is 77%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T15:07:45.092006Z",
     "start_time": "2021-01-27T15:07:45.090269Z"
    }
   },
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('vectorizer', None),\n",
    "    ('sampler', None),\n",
    "    ('classifier', None),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a vectorizer, the max_df is set to ignore terms that will appear in more than the % of the documents, this cuts out words that appear too frequently. Additionally the min_df is used to remove terms that are appearing too infrequently. Selecting the following parameters, the vectorizer will ignore terms that appear in more than 90-95% of the documents & terms that only appear in < 2,3,4 documents. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T15:07:45.095425Z",
     "start_time": "2021-01-27T15:07:45.092968Z"
    }
   },
   "outputs": [],
   "source": [
    "nb_param_grid = [{\n",
    "        # vectorisers to try: count vectoriser, tf-idf vectoriser\n",
    "        'vectorizer': [CountVectorizer(stop_words = stop_words),\n",
    "                       TfidfVectorizer(stop_words = stop_words)],\n",
    "        # feature selection by max df\n",
    "        'vectorizer__max_df': [.95, .90],\n",
    "        'vectorizer__min_df' : [2,3,4],\n",
    "        'vectorizer__ngram_range': [(1,2),(1,3),(2,3)],\n",
    "    \n",
    "        #Sampler\n",
    "        'sampler': [SMOTE(random_state=42)],\n",
    "\n",
    "        # models to test: multinomial Naive Bayes and logistic regression\n",
    "        'classifier': [MultinomialNB()] \n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T15:07:45.098993Z",
     "start_time": "2021-01-27T15:07:45.096508Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_param_grid = [{\n",
    "        # vectorisers to try: count vectoriser, tf-idf vectoriser\n",
    "        'vectorizer': [CountVectorizer(stop_words = stop_words),\n",
    "                       TfidfVectorizer(stop_words = stop_words)],\n",
    "        # feature selection by max df\n",
    "        'vectorizer__max_df': [.95, .90],\n",
    "        'vectorizer__min_df' : [2,3,4],\n",
    "        'vectorizer__ngram_range': [(1,2),(1,3),(2,3)],\n",
    "    \n",
    "        #Sampler\n",
    "        'sampler': [SMOTE(random_state=42)],\n",
    "\n",
    "        # models to test: multinomial Naive Bayes and logistic regression\n",
    "        'classifier': [LogisticRegression()] \n",
    "    }]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaned text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaned text NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T15:26:44.501004Z",
     "start_time": "2021-01-27T15:07:45.099982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 18.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9519711574824987\n",
      "Test Score: 0.8457377832377833\n"
     ]
    }
   ],
   "source": [
    "nb_cleaned_text = GridSearchCV(pl, cv=5, param_grid = nb_param_grid, scoring = 'accuracy', verbose = 1, n_jobs = -1) \n",
    "nb_cleaned_text.fit(X_train, y_train)\n",
    "nb_y_pred = nb_cleaned_text.predict(X_test)\n",
    "\n",
    "print('Train Score:', nb_cleaned_text.score(X_train, y_train))\n",
    "print('Test Score:', nb_cleaned_text.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T15:26:56.585933Z",
     "start_time": "2021-01-27T15:26:44.506214Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/nb_cleaned_text.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(nb_cleaned_text.best_estimator_, 'models/nb_cleaned_text.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T15:27:12.139935Z",
     "start_time": "2021-01-27T15:26:56.586895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC on best params: 0.9833932575605958\n",
      "Validation AUC on best params: 0.858733253987892\n",
      "\n",
      "[[42160  3078]\n",
      " [ 5963  7407]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90     45238\n",
      "           1       0.71      0.55      0.62     13370\n",
      "\n",
      "    accuracy                           0.85     58608\n",
      "   macro avg       0.79      0.74      0.76     58608\n",
      "weighted avg       0.84      0.85      0.84     58608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = nb_cleaned_text.predict_proba(X_train)[:,1]\n",
    "y_test_pred = nb_cleaned_text.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Scoring on testidation data with best params\n",
    "print(f'Training AUC on best params: {roc_auc_score(y_train, y_train_pred)}')\n",
    "    \n",
    "print(f'Validation AUC on best params: {roc_auc_score(y_test, y_test_pred)}')\n",
    "\n",
    "# Printing Confusion Matrix and Scoring reports\n",
    "print()\n",
    "print(confusion_matrix(y_test, nb_cleaned_text.predict(X_test)))\n",
    "print()\n",
    "print(classification_report(y_test, nb_cleaned_text.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaned text LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T15:48:38.853423Z",
     "start_time": "2021-01-27T15:27:12.140931Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 20.8min finished\n"
     ]
    }
   ],
   "source": [
    "lr_cleaned_text = GridSearchCV(pl, cv=5, param_grid = lr_param_grid, scoring = 'accuracy', verbose = 1, n_jobs = -1) \n",
    "lr_cleaned_text.fit(X_train, y_train)\n",
    "lr_y_pred = lr_cleaned_text.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T17:58:23.467796Z",
     "start_time": "2021-01-27T17:58:13.021878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.8698052793908783\n",
      "Test Score: 0.7900116025116025\n"
     ]
    }
   ],
   "source": [
    "print('Train Score:', lr_cleaned_text.score(X_train, y_train))\n",
    "print('Test Score:', lr_cleaned_text.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T15:48:50.854667Z",
     "start_time": "2021-01-27T15:48:38.855255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/lr_cleaned_text.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr_cleaned_text.best_estimator_, 'models/lr_cleaned_text.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T15:49:06.420080Z",
     "start_time": "2021-01-27T15:48:50.855761Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC on best params: 0.927\n",
      "Validation AUC on best params: 0.814\n",
      "\n",
      "[[38011  7227]\n",
      " [ 5080  8290]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86     45238\n",
      "           1       0.53      0.62      0.57     13370\n",
      "\n",
      "    accuracy                           0.79     58608\n",
      "   macro avg       0.71      0.73      0.72     58608\n",
      "weighted avg       0.80      0.79      0.80     58608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = lr_cleaned_text.predict_proba(X_train)[:,1]\n",
    "y_test_pred = lr_cleaned_text.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Scoring on testidation data with best params\n",
    "print(f'Training AUC on best params: {round(roc_auc_score(y_train, y_train_pred), 3)}')\n",
    "    \n",
    "print(f'Validation AUC on best params: {round(roc_auc_score(y_test, y_test_pred), 3)}')\n",
    "\n",
    "# Printing Confusion Matrix and Scoring reports\n",
    "print()\n",
    "print(confusion_matrix(y_test, lr_cleaned_text.predict(X_test)))\n",
    "print()\n",
    "print(classification_report(y_test, lr_cleaned_text.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK Lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T15:49:06.423852Z",
     "start_time": "2021-01-27T15:49:06.421129Z"
    }
   },
   "outputs": [],
   "source": [
    "X_n = final['nltk_lem']\n",
    "y_n = final['yta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T15:49:06.580717Z",
     "start_time": "2021-01-27T15:49:06.424848Z"
    }
   },
   "outputs": [],
   "source": [
    "X_n_train, X_n_test, y_n_train, y_n_test = train_test_split(X_n, \n",
    "                                                    y_n,\n",
    "                                                   test_size = 0.33,\n",
    "                                                   random_state = 42,\n",
    "                                                   stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Lem NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T16:09:58.533143Z",
     "start_time": "2021-01-27T15:49:06.581858Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 20.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9503743980637192\n",
      "Test Score: 0.841011466011466\n"
     ]
    }
   ],
   "source": [
    "nb_nltk_lem = GridSearchCV(pl, cv=5, param_grid = nb_param_grid, scoring = 'accuracy', verbose = 1, n_jobs = -1) \n",
    "nb_nltk_lem.fit(X_n_train, y_n_train)\n",
    "nb_y_pred = nb_nltk_lem.predict(X_n_test)\n",
    "\n",
    "print('Train Score:', nb_nltk_lem.score(X_n_train, y_n_train))\n",
    "print('Test Score:', nb_nltk_lem.score(X_n_test, y_n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T16:10:10.290578Z",
     "start_time": "2021-01-27T16:09:58.540402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/nb_nltk_lem.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(nb_nltk_lem.best_estimator_, 'models/nb_nltk_lem.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T16:10:26.049749Z",
     "start_time": "2021-01-27T16:10:10.291622Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC on best params: 0.9822770025395124\n",
      "Validation AUC on best params: 0.8526532042630148\n",
      "\n",
      "[[42038  3200]\n",
      " [ 6118  7252]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     45238\n",
      "           1       0.69      0.54      0.61     13370\n",
      "\n",
      "    accuracy                           0.84     58608\n",
      "   macro avg       0.78      0.74      0.75     58608\n",
      "weighted avg       0.83      0.84      0.83     58608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_n_train_pred = nb_nltk_lem.predict_proba(X_n_train)[:,1]\n",
    "y_n_test_pred = nb_nltk_lem.predict_proba(X_n_test)[:,1]\n",
    "\n",
    "# Scoring on testidation data with best params\n",
    "print(f'Training AUC on best params: {(roc_auc_score(y_n_train, y_n_train_pred))}')\n",
    "    \n",
    "print(f'Validation AUC on best params: {(roc_auc_score(y_n_test, y_n_test_pred))}')\n",
    "\n",
    "# Printing Confusion Matrix and Scoring reports\n",
    "print()\n",
    "print(confusion_matrix(y_n_test, nb_nltk_lem.predict(X_n_test)))\n",
    "print()\n",
    "print(classification_report(y_n_test, nb_nltk_lem.predict(X_n_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Lem LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T16:32:30.747798Z",
     "start_time": "2021-01-27T16:10:26.051225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 21.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9184139976973048\n",
      "Test Score: 0.7387046137046137\n"
     ]
    }
   ],
   "source": [
    "lr_nltk_lem = GridSearchCV(pl, cv=5, param_grid = lr_param_grid, scoring = 'accuracy', verbose = 1, n_jobs = -1) \n",
    "lr_nltk_lem.fit(X_n_train, y_n_train)\n",
    "lr_y_pred = lr_nltk_lem.predict(X_n_test)\n",
    "\n",
    "print('Train Score:', lr_nltk_lem.score(X_n_train, y_n_train))\n",
    "print('Test Score:', lr_nltk_lem.score(X_n_test, y_n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T16:32:42.294868Z",
     "start_time": "2021-01-27T16:32:30.748971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/lr_nltk_lem.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr_nltk_lem.best_estimator_, 'models/lr_nltk_lem.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T16:32:54.987256Z",
     "start_time": "2021-01-27T16:32:42.301017Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC on best params: 0.9725346152819807\n",
      "Validation AUC on best params: 0.7810681323671896\n",
      "\n",
      "[[34829 10409]\n",
      " [ 4905  8465]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.77      0.82     45238\n",
      "           1       0.45      0.63      0.53     13370\n",
      "\n",
      "    accuracy                           0.74     58608\n",
      "   macro avg       0.66      0.70      0.67     58608\n",
      "weighted avg       0.78      0.74      0.75     58608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_n_train_pred = lr_nltk_lem.predict_proba(X_n_train)[:,1]\n",
    "y_n_test_pred = lr_nltk_lem.predict_proba(X_n_test)[:,1]\n",
    "\n",
    "# Scoring on testidation data with best params\n",
    "print(f'Training AUC on best params: {(roc_auc_score(y_n_train, y_n_train_pred))}')\n",
    "    \n",
    "print(f'Validation AUC on best params: {(roc_auc_score(y_n_test, y_n_test_pred))}')\n",
    "\n",
    "# Printing Confusion Matrix and Scoring reports\n",
    "print()\n",
    "print(confusion_matrix(y_n_test, lr_nltk_lem.predict(X_n_test)))\n",
    "print()\n",
    "print(classification_report(y_n_test, lr_nltk_lem.predict(X_n_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T16:32:54.990846Z",
     "start_time": "2021-01-27T16:32:54.989183Z"
    }
   },
   "outputs": [],
   "source": [
    "X_p = final['nltk_pos']\n",
    "y_p = final['yta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T16:32:55.153566Z",
     "start_time": "2021-01-27T16:32:54.991873Z"
    }
   },
   "outputs": [],
   "source": [
    "X_p_train, X_p_test, y_p_train, y_p_test = train_test_split(X_p, \n",
    "                                                    y_p,\n",
    "                                                   test_size = 0.33,\n",
    "                                                   random_state = 42,\n",
    "                                                   stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK POS NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T16:53:54.293733Z",
     "start_time": "2021-01-27T16:32:55.154704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.7min\n",
      "/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 20.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9488952946021127\n",
      "Test Score: 0.8405337155337156\n"
     ]
    }
   ],
   "source": [
    "nb_nltk_pos = GridSearchCV(pl, cv=5, param_grid = nb_param_grid, scoring = 'accuracy', verbose = 1, n_jobs = -1) \n",
    "nb_nltk_pos.fit(X_p_train, y_p_train)\n",
    "nb_y_pred = nb_nltk_pos.predict(X_p_test)\n",
    "\n",
    "print('Train Score:', nb_nltk_pos.score(X_p_train, y_p_train))\n",
    "print('Test Score:', nb_nltk_pos.score(X_p_test, y_p_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T16:54:08.140159Z",
     "start_time": "2021-01-27T16:53:54.304144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/nb_nltk_pos.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(nb_nltk_lem.best_estimator_, 'models/nb_nltk_pos.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T16:54:24.057049Z",
     "start_time": "2021-01-27T16:54:08.141020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC on best params: 0.9813997993959207\n",
      "Validation AUC on best params: 0.8503895734296888\n",
      "\n",
      "[[41978  3260]\n",
      " [ 6086  7284]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     45238\n",
      "           1       0.69      0.54      0.61     13370\n",
      "\n",
      "    accuracy                           0.84     58608\n",
      "   macro avg       0.78      0.74      0.75     58608\n",
      "weighted avg       0.83      0.84      0.83     58608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_p_train_pred = nb_nltk_pos.predict_proba(X_p_train)[:,1]\n",
    "y_p_test_pred = nb_nltk_pos.predict_proba(X_p_test)[:,1]\n",
    "\n",
    "# Scoring on testidation data with best params\n",
    "print(f'Training AUC on best params: {(roc_auc_score(y_p_train, y_p_train_pred))}')\n",
    "    \n",
    "print(f'Validation AUC on best params: {(roc_auc_score(y_p_test, y_p_test_pred))}')\n",
    "\n",
    "# Printing Confusion Matrix and Scoring reports\n",
    "print()\n",
    "print(confusion_matrix(y_p_test, nb_nltk_pos.predict(X_p_test)))\n",
    "print()\n",
    "print(classification_report(y_p_test, nb_nltk_pos.predict(X_p_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy Lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T17:18:38.965744Z",
     "start_time": "2021-01-27T17:18:38.955556Z"
    }
   },
   "outputs": [],
   "source": [
    "X_s = final['spacy_lem']\n",
    "y_s = final['yta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T17:18:40.271774Z",
     "start_time": "2021-01-27T17:18:39.881920Z"
    }
   },
   "outputs": [],
   "source": [
    "X_s_train, X_s_test, y_s_train, y_s_test = train_test_split(X_s, \n",
    "                                                    y_s,\n",
    "                                                   test_size = 0.33,\n",
    "                                                   random_state = 42,\n",
    "                                                   stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Lem NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T17:37:28.605325Z",
     "start_time": "2021-01-27T17:18:42.318785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 18.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9404744896672858\n",
      "Test Score: 0.8327361452361453\n"
     ]
    }
   ],
   "source": [
    "nb_spacy_lem = GridSearchCV(pl, cv=5, param_grid = nb_param_grid, scoring = 'accuracy', verbose = 1, n_jobs = -1) \n",
    "nb_spacy_lem.fit(X_s_train, y_s_train)\n",
    "nb_y_pred = nb_spacy_lem.predict(X_s_test)\n",
    "\n",
    "print('Train Score:', nb_spacy_lem.score(X_s_train, y_s_train))\n",
    "print('Test Score:', nb_spacy_lem.score(X_s_test, y_s_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T17:37:38.325269Z",
     "start_time": "2021-01-27T17:37:28.612627Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/nb_spacy_lem.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(nb_spacy_lem.best_estimator_, 'models/nb_spacy_lem.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T17:37:51.380027Z",
     "start_time": "2021-01-27T17:37:38.327540Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC on best params: 0.9774156666829124\n",
      "Validation AUC on best params: 0.8441512111643025\n",
      "\n",
      "[[41280  3958]\n",
      " [ 5845  7525]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89     45238\n",
      "           1       0.66      0.56      0.61     13370\n",
      "\n",
      "    accuracy                           0.83     58608\n",
      "   macro avg       0.77      0.74      0.75     58608\n",
      "weighted avg       0.83      0.83      0.83     58608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_s_train_pred = nb_spacy_lem.predict_proba(X_s_train)[:,1]\n",
    "y_s_test_pred = nb_spacy_lem.predict_proba(X_s_test)[:,1]\n",
    "\n",
    "# Scoring on testidation data with best params\n",
    "print(f'Training AUC on best params: {(roc_auc_score(y_s_train, y_s_train_pred))}')\n",
    "    \n",
    "print(f'Validation AUC on best params: {(roc_auc_score(y_s_test, y_s_test_pred))}')\n",
    "\n",
    "# Printing Confusion Matrix and Scoring reports\n",
    "print()\n",
    "print(confusion_matrix(y_s_test, nb_spacy_lem.predict(X_s_test)))\n",
    "print()\n",
    "print(classification_report(y_s_test, nb_spacy_lem.predict(X_s_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Lem LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T17:57:52.280525Z",
     "start_time": "2021-01-27T17:37:51.381328Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 19.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.8592666672269331\n",
      "Test Score: 0.7788356538356538\n"
     ]
    }
   ],
   "source": [
    "lr_spacy_lem = GridSearchCV(pl, cv=5, param_grid = lr_param_grid, scoring = 'accuracy', verbose = 1, n_jobs = -1) \n",
    "lr_spacy_lem.fit(X_s_train, y_s_train)\n",
    "lr_y_pred = lr_spacy_lem.predict(X_s_test)\n",
    "\n",
    "print('Train Score:', lr_spacy_lem.score(X_s_train, y_s_train))\n",
    "print('Test Score:', lr_spacy_lem.score(X_s_test, y_s_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T17:58:01.939788Z",
     "start_time": "2021-01-27T17:57:52.282367Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/lr_spacy_lem.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr_spacy_lem.best_estimator_, 'models/lr_spacy_lem.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T17:58:04.300245Z",
     "start_time": "2021-01-27T17:58:01.942719Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_spacy_lem = joblib.load('lr_spacy_lem.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T17:58:13.019703Z",
     "start_time": "2021-01-27T17:58:04.301343Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC on best params: 0.9123322783414028\n",
      "Validation AUC on best params: 0.8011109067201233\n",
      "\n",
      "[[37254  7984]\n",
      " [ 5165  8205]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85     45238\n",
      "           1       0.51      0.61      0.56     13370\n",
      "\n",
      "    accuracy                           0.78     58608\n",
      "   macro avg       0.69      0.72      0.70     58608\n",
      "weighted avg       0.79      0.78      0.78     58608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_s_train_pred = lr_spacy_lem.predict_proba(X_s_train)[:,1]\n",
    "y_s_test_pred = lr_spacy_lem.predict_proba(X_s_test)[:,1]\n",
    "\n",
    "# Scoring on testidation data with best params\n",
    "print(f'Training AUC on best params: {(roc_auc_score(y_s_train, y_s_train_pred))}')\n",
    "    \n",
    "print(f'Validation AUC on best params: {(roc_auc_score(y_s_test, y_s_test_pred))}')\n",
    "\n",
    "# Printing Confusion Matrix and Scoring reports\n",
    "print()\n",
    "print(confusion_matrix(y_s_test, lr_spacy_lem.predict(X_s_test)))\n",
    "print()\n",
    "print(classification_report(y_s_test, lr_spacy_lem.predict(X_s_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model & Evaluation\n",
    "Surprisingly, the model that generated with the highest accuracy was from the cleaned_text dataset that only used limited text processing with no lemmatizers. This model had a test score of 0.846 along with the highest precision for \n",
    "\n",
    "Let's pull out the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T22:11:47.352619Z",
     "start_time": "2021-01-27T22:11:40.314358Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#Load in the Cleaned_text multinomial bayes model\n",
    "ctnb = joblib.load('models/nb_cleaned_text.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T22:11:50.029330Z",
     "start_time": "2021-01-27T22:11:50.024836Z"
    }
   },
   "outputs": [],
   "source": [
    "tf = ctnb.named_steps['vectorizer']\n",
    "nb = ctnb.named_steps['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T22:12:09.776919Z",
     "start_time": "2021-01-27T22:11:50.347878Z"
    }
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame(data = [tf.get_feature_names(), nb.feature_log_prob_[0]])\n",
    "features = features.transpose()\n",
    "features.columns = ['features', 'coef']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T22:12:10.622593Z",
     "start_time": "2021-01-27T22:12:09.778245Z"
    }
   },
   "outputs": [],
   "source": [
    "top = features.sort_values('coef', ascending=True).head(25)\n",
    "bot = features.sort_values('coef', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T22:12:10.630463Z",
     "start_time": "2021-01-27T22:12:10.624547Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>325103</th>\n",
       "      <td>quotes needed</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206883</th>\n",
       "      <td>keep decision</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206891</th>\n",
       "      <td>keep dick</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318200</th>\n",
       "      <td>probably feels utterly</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393992</th>\n",
       "      <td>support structure</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393994</th>\n",
       "      <td>support stupid</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421539</th>\n",
       "      <td>transition whatever</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206914</th>\n",
       "      <td>keep doubt</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421534</th>\n",
       "      <td>transition need</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421533</th>\n",
       "      <td>transition hard</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206933</th>\n",
       "      <td>keep emergency</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206942</th>\n",
       "      <td>keep engaged</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32135</th>\n",
       "      <td>back folding</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32136</th>\n",
       "      <td>back folding laundry</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421520</th>\n",
       "      <td>transgender man</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32138</th>\n",
       "      <td>back foot</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421541</th>\n",
       "      <td>transitional period</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318162</th>\n",
       "      <td>probably even know</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32110</th>\n",
       "      <td>back feet one</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421574</th>\n",
       "      <td>transphobic asshole</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206687</th>\n",
       "      <td>keep apologizing</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206702</th>\n",
       "      <td>keep awake</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393968</th>\n",
       "      <td>support sisters</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318248</th>\n",
       "      <td>probably gf</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206754</th>\n",
       "      <td>keep blaming</td>\n",
       "      <td>-13.7789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      features     coef\n",
       "325103           quotes needed -13.7789\n",
       "206883           keep decision -13.7789\n",
       "206891               keep dick -13.7789\n",
       "318200  probably feels utterly -13.7789\n",
       "393992       support structure -13.7789\n",
       "393994          support stupid -13.7789\n",
       "421539     transition whatever -13.7789\n",
       "206914              keep doubt -13.7789\n",
       "421534         transition need -13.7789\n",
       "421533         transition hard -13.7789\n",
       "206933          keep emergency -13.7789\n",
       "206942            keep engaged -13.7789\n",
       "32135             back folding -13.7789\n",
       "32136     back folding laundry -13.7789\n",
       "421520         transgender man -13.7789\n",
       "32138                back foot -13.7789\n",
       "421541     transitional period -13.7789\n",
       "318162      probably even know -13.7789\n",
       "32110            back feet one -13.7789\n",
       "421574     transphobic asshole -13.7789\n",
       "206687        keep apologizing -13.7789\n",
       "206702              keep awake -13.7789\n",
       "393968         support sisters -13.7789\n",
       "318248             probably gf -13.7789\n",
       "206754            keep blaming -13.7789"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top predictors for the model contain far more negative language than the bottom 25. Several of the n-gram combinations use language like 'stupid' or 'asshole'. Additionally, many of the descriptors are actions, using  which indicate that when voting for YTA, people tend to use more active language such as 'keep *action-ing*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T22:12:10.636851Z",
     "start_time": "2021-01-27T22:12:10.631676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226845</th>\n",
       "      <td>like</td>\n",
       "      <td>-6.75228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459722</th>\n",
       "      <td>would</td>\n",
       "      <td>-6.88085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153347</th>\n",
       "      <td>get</td>\n",
       "      <td>-6.91859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301833</th>\n",
       "      <td>people</td>\n",
       "      <td>-7.19734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130384</th>\n",
       "      <td>family</td>\n",
       "      <td>-7.23697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437842</th>\n",
       "      <td>want</td>\n",
       "      <td>-7.24865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414743</th>\n",
       "      <td>time</td>\n",
       "      <td>-7.27165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295630</th>\n",
       "      <td>parents</td>\n",
       "      <td>-7.28151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285727</th>\n",
       "      <td>one</td>\n",
       "      <td>-7.28863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118006</th>\n",
       "      <td>even</td>\n",
       "      <td>-7.34657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260593</th>\n",
       "      <td>mom</td>\n",
       "      <td>-7.37777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271295</th>\n",
       "      <td>need</td>\n",
       "      <td>-7.37784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167484</th>\n",
       "      <td>good</td>\n",
       "      <td>-7.39585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244168</th>\n",
       "      <td>make</td>\n",
       "      <td>-7.40369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409479</th>\n",
       "      <td>think</td>\n",
       "      <td>-7.40919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209762</th>\n",
       "      <td>kids</td>\n",
       "      <td>-7.42403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213387</th>\n",
       "      <td>know</td>\n",
       "      <td>-7.43354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12902</th>\n",
       "      <td>also</td>\n",
       "      <td>-7.44437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340543</th>\n",
       "      <td>right</td>\n",
       "      <td>-7.44695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162833</th>\n",
       "      <td>go</td>\n",
       "      <td>-7.45458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443318</th>\n",
       "      <td>way</td>\n",
       "      <td>-7.47081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262709</th>\n",
       "      <td>money</td>\n",
       "      <td>-7.47693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366066</th>\n",
       "      <td>sister</td>\n",
       "      <td>-7.49649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273857</th>\n",
       "      <td>needs</td>\n",
       "      <td>-7.50549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402700</th>\n",
       "      <td>tell</td>\n",
       "      <td>-7.51696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       features     coef\n",
       "226845     like -6.75228\n",
       "459722    would -6.88085\n",
       "153347      get -6.91859\n",
       "301833   people -7.19734\n",
       "130384   family -7.23697\n",
       "437842     want -7.24865\n",
       "414743     time -7.27165\n",
       "295630  parents -7.28151\n",
       "285727      one -7.28863\n",
       "118006     even -7.34657\n",
       "260593      mom -7.37777\n",
       "271295     need -7.37784\n",
       "167484     good -7.39585\n",
       "244168     make -7.40369\n",
       "409479    think -7.40919\n",
       "209762     kids -7.42403\n",
       "213387     know -7.43354\n",
       "12902      also -7.44437\n",
       "340543    right -7.44695\n",
       "162833       go -7.45458\n",
       "443318      way -7.47081\n",
       "262709    money -7.47693\n",
       "366066   sister -7.49649\n",
       "273857    needs -7.50549\n",
       "402700     tell -7.51696"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the predictors for NTA they are mostly 1 word n-grams. A common theme in there seems to be family, 'parents, mom, sister, kids'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's predict the final chosen model to the test data and have a look at the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T21:12:06.038504Z",
     "start_time": "2021-01-27T21:12:05.864777Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>yta</th>\n",
       "      <th>nta</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>nltk_lem</th>\n",
       "      <th>nltk_pos</th>\n",
       "      <th>spacy_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k4owfz</td>\n",
       "      <td>Is it possible for mods to pin some ‘YTA’ thre...</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>possible mods pin threads front page pretty pl...</td>\n",
       "      <td>possible mod pin thread front page pretty plea...</td>\n",
       "      <td>possible mod pin thread front page pretty plea...</td>\n",
       "      <td>possible mod pin thread page pretty single pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k4owfz</td>\n",
       "      <td>Is there anything which could be done about th...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>anything could done section posts op get massi...</td>\n",
       "      <td>anything could done section post op get massiv...</td>\n",
       "      <td>anything could do section post op get massive ...</td>\n",
       "      <td>section post op massive majority respond small...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k4owfz</td>\n",
       "      <td>This sub has a really huge double standards pr...</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sub really huge double standards problem read ...</td>\n",
       "      <td>sub really huge double standard problem read p...</td>\n",
       "      <td>sub really huge double standard problem read p...</td>\n",
       "      <td>sub huge double standard problem read post hus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k4owfz</td>\n",
       "      <td>Or... You can pass your judgement, upvote the ...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>pass judgement upvote judgements agree let chi...</td>\n",
       "      <td>pas judgement upvote judgement agree let chip ...</td>\n",
       "      <td>pas judgement upvote judgement agree let chip ...</td>\n",
       "      <td>pass judgement upvote judgement agree let chip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k4owfz</td>\n",
       "      <td>I do upvote any YTA post and don’t upvote any ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>upvote post upvote posts regardless want ratio...</td>\n",
       "      <td>upvote post upvote post regardless want ratio ...</td>\n",
       "      <td>upvote post upvote post regardless want ratio ...</td>\n",
       "      <td>upvote post upvote post regardless want ratio ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id                                       comment_text  comment_score  \\\n",
       "0  k4owfz  Is it possible for mods to pin some ‘YTA’ thre...             23   \n",
       "1  k4owfz  Is there anything which could be done about th...              7   \n",
       "2  k4owfz  This sub has a really huge double standards pr...             -3   \n",
       "3  k4owfz  Or... You can pass your judgement, upvote the ...             13   \n",
       "4  k4owfz  I do upvote any YTA post and don’t upvote any ...              3   \n",
       "\n",
       "   yta  nta                                       cleaned_text  \\\n",
       "0    1    1  possible mods pin threads front page pretty pl...   \n",
       "1    1    1  anything could done section posts op get massi...   \n",
       "2    1    1  sub really huge double standards problem read ...   \n",
       "3    1    1  pass judgement upvote judgements agree let chi...   \n",
       "4    1    1  upvote post upvote posts regardless want ratio...   \n",
       "\n",
       "                                            nltk_lem  \\\n",
       "0  possible mod pin thread front page pretty plea...   \n",
       "1  anything could done section post op get massiv...   \n",
       "2  sub really huge double standard problem read p...   \n",
       "3  pas judgement upvote judgement agree let chip ...   \n",
       "4  upvote post upvote post regardless want ratio ...   \n",
       "\n",
       "                                            nltk_pos  \\\n",
       "0  possible mod pin thread front page pretty plea...   \n",
       "1  anything could do section post op get massive ...   \n",
       "2  sub really huge double standard problem read p...   \n",
       "3  pas judgement upvote judgement agree let chip ...   \n",
       "4  upvote post upvote post regardless want ratio ...   \n",
       "\n",
       "                                           spacy_lem  \n",
       "0  possible mod pin thread page pretty single pos...  \n",
       "1  section post op massive majority respond small...  \n",
       "2  sub huge double standard problem read post hus...  \n",
       "3  pass judgement upvote judgement agree let chip...  \n",
       "4  upvote post upvote post regardless want ratio ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('datasets/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T21:12:06.493127Z",
     "start_time": "2021-01-27T21:12:06.484459Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T21:12:14.382905Z",
     "start_time": "2021-01-27T21:12:07.018079Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#Load in the Cleaned_text multinomial bayes model\n",
    "ctnb = joblib.load('models/nb_cleaned_text.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T21:12:14.625126Z",
     "start_time": "2021-01-27T21:12:14.384258Z"
    }
   },
   "outputs": [],
   "source": [
    "test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T21:13:06.628235Z",
     "start_time": "2021-01-27T21:13:06.510843Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4640047 , 0.5359953 ],\n",
       "       [0.70148627, 0.29851373],\n",
       "       [0.6083726 , 0.3916274 ],\n",
       "       [0.45207695, 0.54792305],\n",
       "       [0.4365492 , 0.5634508 ],\n",
       "       [0.87443529, 0.12556471],\n",
       "       [0.66427474, 0.33572526],\n",
       "       [0.50913708, 0.49086292],\n",
       "       [0.46703686, 0.53296314],\n",
       "       [0.83062604, 0.16937396]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba = ctnb.predict_proba(test['cleaned_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T21:13:27.018811Z",
     "start_time": "2021-01-27T21:13:27.010762Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4640047 , 0.5359953 ],\n",
       "       [0.70148627, 0.29851373],\n",
       "       [0.6083726 , 0.3916274 ],\n",
       "       [0.45207695, 0.54792305],\n",
       "       [0.4365492 , 0.5634508 ],\n",
       "       [0.87443529, 0.12556471],\n",
       "       [0.66427474, 0.33572526],\n",
       "       [0.50913708, 0.49086292],\n",
       "       [0.46703686, 0.53296314],\n",
       "       [0.83062604, 0.16937396]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T21:13:42.838116Z",
     "start_time": "2021-01-27T21:13:42.833447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T21:14:23.689601Z",
     "start_time": "2021-01-27T21:14:23.683500Z"
    }
   },
   "outputs": [],
   "source": [
    "test_preds = pd.DataFrame(predict_proba, columns = ['NTA', 'YTA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T21:14:24.239917Z",
     "start_time": "2021-01-27T21:14:24.233072Z"
    }
   },
   "outputs": [],
   "source": [
    "test_preds['comment'] = test['comment_text'].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T21:14:24.653460Z",
     "start_time": "2021-01-27T21:14:24.646332Z"
    }
   },
   "outputs": [],
   "source": [
    "test_preds['predicted'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T21:14:53.619438Z",
     "start_time": "2021-01-27T21:14:53.602827Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NTA</th>\n",
       "      <th>YTA</th>\n",
       "      <th>comment</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.874435</td>\n",
       "      <td>0.125565</td>\n",
       "      <td>In this specific case I see OP trying to defle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.830626</td>\n",
       "      <td>0.169374</td>\n",
       "      <td>NTA for serving the salad or not changing the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.758963</td>\n",
       "      <td>0.241037</td>\n",
       "      <td>NTA, because Claire is just overreacting, but ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.786301</td>\n",
       "      <td>0.213699</td>\n",
       "      <td>This woman is LITERAL garbage and YTA for brin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.811574</td>\n",
       "      <td>0.188426</td>\n",
       "      <td>YTA if you don't walk away from such a selfish...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NTA       YTA                                            comment  \\\n",
       "5   0.874435  0.125565  In this specific case I see OP trying to defle...   \n",
       "9   0.830626  0.169374  NTA for serving the salad or not changing the ...   \n",
       "10  0.758963  0.241037  NTA, because Claire is just overreacting, but ...   \n",
       "11  0.786301  0.213699  This woman is LITERAL garbage and YTA for brin...   \n",
       "13  0.811574  0.188426  YTA if you don't walk away from such a selfish...   \n",
       "\n",
       "    predicted  \n",
       "5           0  \n",
       "9           0  \n",
       "10          0  \n",
       "11          0  \n",
       "13          0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_nta = test_preds[test_preds['NTA'] > 0.75]\n",
    "r_nta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T21:19:19.345035Z",
     "start_time": "2021-01-27T21:19:19.328831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NTA</th>\n",
       "      <th>YTA</th>\n",
       "      <th>comment</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.224109</td>\n",
       "      <td>0.775891</td>\n",
       "      <td>NTA. She dumps her kids on you unannounced and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.033502</td>\n",
       "      <td>0.966498</td>\n",
       "      <td>YTA *and* a horrible mother. I feel so sad for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.240079</td>\n",
       "      <td>0.759921</td>\n",
       "      <td>YTA to your wife as you ARE stating that you d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.235578</td>\n",
       "      <td>0.764422</td>\n",
       "      <td>YTA\\n\\nYou're the one in the same house as you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.240677</td>\n",
       "      <td>0.759323</td>\n",
       "      <td>YTA. Absolutely. And as a teacher, let me teac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NTA       YTA                                            comment  \\\n",
       "23   0.224109  0.775891  NTA. She dumps her kids on you unannounced and...   \n",
       "79   0.033502  0.966498  YTA *and* a horrible mother. I feel so sad for...   \n",
       "103  0.240079  0.759921  YTA to your wife as you ARE stating that you d...   \n",
       "125  0.235578  0.764422  YTA\\n\\nYou're the one in the same house as you...   \n",
       "126  0.240677  0.759323  YTA. Absolutely. And as a teacher, let me teac...   \n",
       "\n",
       "     predicted  \n",
       "23           1  \n",
       "79           1  \n",
       "103          1  \n",
       "125          1  \n",
       "126          1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_yta = test_preds[test_preds['YTA'] > 0.75]\n",
    "r_yta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T21:18:39.476751Z",
     "start_time": "2021-01-27T21:18:39.470059Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"YTA - you're happy to dump your kids on her, and you make an uneducated guess (you can't even name any of the reptiles) as to how dirty or dangerous they are over her advice as an educator.    Then you get mad when she tells your kids the truth!   There is not a single comment in your narrative that would make you NTA.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_yta['comment'][263] #0.76 #YTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T21:36:40.457749Z",
     "start_time": "2021-01-27T21:36:40.450625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YTA to your wife as you ARE stating that you do not trust her.  It takes two to tango and your ex gf is at fault the same as your brother.  You wife is not your ex girlfriend, but you are treating her as if she were.  NTA to your brother as you have the right to want him out before you leave no matter the reasoning.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_yta['comment'][103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T21:19:46.800899Z",
     "start_time": "2021-01-27T21:19:46.783181Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NTA</th>\n",
       "      <th>YTA</th>\n",
       "      <th>comment</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.874435</td>\n",
       "      <td>0.125565</td>\n",
       "      <td>In this specific case I see OP trying to defle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.830626</td>\n",
       "      <td>0.169374</td>\n",
       "      <td>NTA for serving the salad or not changing the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.758963</td>\n",
       "      <td>0.241037</td>\n",
       "      <td>NTA, because Claire is just overreacting, but ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.786301</td>\n",
       "      <td>0.213699</td>\n",
       "      <td>This woman is LITERAL garbage and YTA for brin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.811574</td>\n",
       "      <td>0.188426</td>\n",
       "      <td>YTA if you don't walk away from such a selfish...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NTA       YTA                                            comment  \\\n",
       "5   0.874435  0.125565  In this specific case I see OP trying to defle...   \n",
       "9   0.830626  0.169374  NTA for serving the salad or not changing the ...   \n",
       "10  0.758963  0.241037  NTA, because Claire is just overreacting, but ...   \n",
       "11  0.786301  0.213699  This woman is LITERAL garbage and YTA for brin...   \n",
       "13  0.811574  0.188426  YTA if you don't walk away from such a selfish...   \n",
       "\n",
       "    predicted  \n",
       "5           0  \n",
       "9           0  \n",
       "10          0  \n",
       "11          0  \n",
       "13          0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_nta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T20:47:21.344723Z",
     "start_time": "2021-01-27T20:47:21.328345Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YTA</th>\n",
       "      <th>NTA</th>\n",
       "      <th>comment</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>0.228369</td>\n",
       "      <td>0.771631</td>\n",
       "      <td>NTA for not going but YTA for being upset she ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>0.165916</td>\n",
       "      <td>0.834084</td>\n",
       "      <td>Why are people saying YTA?  NTA: you have a ri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>0.049038</td>\n",
       "      <td>0.950962</td>\n",
       "      <td>YTA. That's rude. If you simply suggested ther...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>0.059344</td>\n",
       "      <td>0.940656</td>\n",
       "      <td>YTA bordering on E s h.\\n\\n\\nShe isn't respect...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.204134</td>\n",
       "      <td>0.795866</td>\n",
       "      <td>Half NTA, Half YTA.  I would say that it's a f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          YTA       NTA                                            comment  \\\n",
       "723  0.228369  0.771631  NTA for not going but YTA for being upset she ...   \n",
       "776  0.165916  0.834084  Why are people saying YTA?  NTA: you have a ri...   \n",
       "833  0.049038  0.950962  YTA. That's rude. If you simply suggested ther...   \n",
       "834  0.059344  0.940656  YTA bordering on E s h.\\n\\n\\nShe isn't respect...   \n",
       "863  0.204134  0.795866  Half NTA, Half YTA.  I would say that it's a f...   \n",
       "\n",
       "     predicted  \n",
       "723          1  \n",
       "776          1  \n",
       "833          1  \n",
       "834          1  \n",
       "863          1  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_nta.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T21:29:39.348659Z",
     "start_time": "2021-01-27T21:29:39.341346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"YTA if you don't walk away from such a selfish person that she thinks a WHEELCHAIR bound child should be upstairs solely because a room that MIGHT have guests in it is larger.\\n\\nNTA for insisting the downstairs room is rightly more suitable for her. \\n\\nIf your fiance is fighting about this now, do you really trust her to be a good mother to your daughter when you aren't around?\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_nta['comment'][13] #0.81 # NTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, through training on 4 types of text processing using a variety of vectorizers and classifers I identified a model that predicted if a person would vote YTA or NTA to a 85.9% beating out the baseline accuracy of 77%. Although more advanced techniques were used in the lemmatization of the text, the simplest text model beat out most of the other models. \n",
    "\n",
    "The end model seems to pick up reliably on the text. For example, in the above comment, the model was able to pick up on the language use although active strong language was used. From the extraction of the coefs, I would assume the model would recognize such language use as 'YTA' rather than the strong 'NTA\" the post was given. \n",
    "\n",
    "Due to time restraints many of the aspects of the project were not explored. Future improvements to the project could be to access the post texts to do a word study between the comments and the original post, common words used between the two for example. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "228.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
