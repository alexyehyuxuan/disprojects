{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction & Problem Statement \n",
    "\n",
    "Reddit is a social media website focused on social news aggregation, web content rating, and discussions. Members contribute content through different subreddits(community-managed pages) that are then voted up or down by other members of the community. Scored through an algorithm that measures votes and among other things time that the post has been there, which assures that new content will always float to the top. Submissions with a high enough score will make it to the front page of reddit. Reddit's subreddits have created interesting niche communities that have flourished and may not have survived on other parts of the internet.\n",
    "\n",
    "Reddit/r/AmitheAsshole is one such niche community that has arisen with a unique premise that aims to both help and entertain users. The premise is such, people post situations that they have found themselves in in which they feel they will be perceived as an 'asshole'. Commenters reply to the original posters situation and vote on them by using coded language designated in the subreddit rules. There are times, however, that posters can't make up their minds, and leave some form of vaguely worded message with a conflicting vote.  \n",
    "\n",
    "This project aims to create a model that can use comments to predict on comments that contain both YTA & NTA.\n",
    "\n",
    "To that end, 4 forms of different lemmatizations were created and put through word-frequency based classification models which were evaluated based on accuracy. The final production model ended up having an accuracy score of 84.6%. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T06:09:37.377910Z",
     "start_time": "2021-01-24T06:09:36.800448Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import praw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRAW\n",
    "Using Python Reddit API Wrapper (PRAW) I pulled posts and the comments within the posts. \n",
    "\n",
    "For the comments, I pulled \n",
    "- comment_text: The body text of the comment \n",
    "- comment_dist: Comment Distinguished (Moderator posts for cleaning) \n",
    "- comment_score: Comment Score (Number of upvotes for the comment)\n",
    "- comment_parentpost_id: The parent post ID\n",
    "\n",
    "Parent posts:\n",
    "- post_title\n",
    "- post_text\n",
    "- post_id\n",
    "- post_dist\n",
    "- post_score\n",
    "- post_upvoteratio\n",
    "- post_date\n",
    "\n",
    "The intention to pull the parent posts were for further research to show the predicted comments with word similarity to the parent text. However due to a lack of time, this wasn't followed up on. \n",
    "\n",
    "In total, 4 pulls were made each a week apart with the exception of the fifth pull due to complications I will discuss in the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T16:02:17.779437Z",
     "start_time": "2021-01-27T16:02:17.578945Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'praw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e6a1bef2ab85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Acessing the reddit api\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m reddit = praw.Reddit(client_id=\"9tAy2O858UyM-Q\",#client id\n\u001b[0m\u001b[0;32m      3\u001b[0m                      \u001b[0mclient_secret\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"wRRhIAzTIgVBvcsvJftgZfK6dC4Nsg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#client secret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                      user_agent=\"alex_bot\") #user agent name\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'praw' is not defined"
     ]
    }
   ],
   "source": [
    "#Acessing the reddit api\n",
    "reddit = praw.Reddit(client_id=\"9tAy2O858UyM-Q\",#client id\n",
    "                     client_secret=\"wRRhIAzTIgVBvcsvJftgZfK6dC4Nsg\", #client secret\n",
    "                     user_agent=\"alex_bot\") #user agent name\n",
    "\n",
    "# define custom scraping function\n",
    "def scrape_subreddit(subreddit, postlimit=1000):\n",
    "    \n",
    "    subreddit = reddit.subreddit(subreddit)\n",
    "\n",
    "    post_title = []\n",
    "    post_text = []\n",
    "    post_id = []\n",
    "    post_dist = []\n",
    "    post_score = []\n",
    "    post_upvoteratio = []\n",
    "    post_date = []\n",
    "    comment_text = []\n",
    "    comment_dist = []\n",
    "    comment_score = []\n",
    "    comment_parentpost_id = []\n",
    "\n",
    "    # collect from posts sorted by hot\n",
    "    for submission in subreddit.hot(limit = postlimit):\n",
    "        # collect information on post\n",
    "        post_title.append(submission.title)\n",
    "        post_text.append(submission.selftext)\n",
    "        post_id.append(submission.id)\n",
    "        post_dist.append(submission.distinguished)\n",
    "        post_score.append(submission.score)\n",
    "        post_upvoteratio.append(submission.upvote_ratio)\n",
    "        post_date.append(submission.created_utc)\n",
    "\n",
    "        # collect all comments on each post\n",
    "        submission.comments.replace_more(limit = None)\n",
    "        for comment in submission.comments.list():     \n",
    "            comment_text.append(comment.body)\n",
    "            comment_dist.append(comment.distinguished)\n",
    "            comment_score.append(comment.score)\n",
    "            comment_parentpost_id.append(submission.id)\n",
    " \n",
    "    # put posts into a df\n",
    "    df_post = pd.DataFrame({'title': post_title,\n",
    "                              'id': post_id,\n",
    "                            'date_created':post_date,\n",
    "                              'text': post_text,\n",
    "                              'distinguished': post_dist,\n",
    "                              'score': post_score,\n",
    "                              'upvote_ratio': post_upvoteratio})\n",
    "    df_post['date_created'] = pd.to_datetime(df_post['date_created'], unit = 's')\n",
    "    \n",
    "    # put comments into a df\n",
    "    df_comments = pd.DataFrame({'post_id': comment_parentpost_id,\n",
    "                              'comment_text': comment_text,\n",
    "                              'comment_distinguished': comment_dist,\n",
    "                              'comment_score': comment_score})\n",
    "    \n",
    "    return df_post, df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.9 s, sys: 3.47 s, total: 59.4 s\n",
      "Wall time: 31min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# scrape\n",
    "aita_posts, aita_comments = scrape_subreddit('AmiTheAsshole')\n",
    "aita_posts.to_csv('datasets/posts.csv', index=False)\n",
    "aita_comments.to_csv('datasets/comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second Pull 2/1/21\n",
    "#Acessing the reddit api\n",
    "reddit = praw.Reddit(client_id=\"9tAy2O858UyM-Q\",#client id\n",
    "                     client_secret=\"wRRhIAzTIgVBvcsvJftgZfK6dC4Nsg\", #client secret\n",
    "                     user_agent=\"alex_bot\") #user agent name\n",
    "\n",
    "# define custom scraping function\n",
    "def scrape_subreddit(subreddit, postlimit=1000):\n",
    "    \n",
    "    subreddit = reddit.subreddit(subreddit)\n",
    "\n",
    "    post_title = []\n",
    "    post_text = []\n",
    "    post_id = []\n",
    "    post_dist = []\n",
    "    post_score = []\n",
    "    post_upvoteratio = []\n",
    "    post_date = []\n",
    "    comment_text = []\n",
    "    comment_dist = []\n",
    "    comment_score = []\n",
    "    comment_parentpost_id = []\n",
    "\n",
    "    # collect from posts sorted by hot\n",
    "    for submission in subreddit.hot(limit = postlimit):\n",
    "        # collect information on post\n",
    "        post_title.append(submission.title)\n",
    "        post_text.append(submission.selftext)\n",
    "        post_id.append(submission.id)\n",
    "        post_dist.append(submission.distinguished)\n",
    "        post_score.append(submission.score)\n",
    "        post_upvoteratio.append(submission.upvote_ratio)\n",
    "        post_date.append(submission.created_utc)\n",
    "\n",
    "        # collect all comments on each post\n",
    "        submission.comments.replace_more(limit = None)\n",
    "        for comment in submission.comments.list():     \n",
    "            comment_text.append(comment.body)\n",
    "            comment_dist.append(comment.distinguished)\n",
    "            comment_score.append(comment.score)\n",
    "            comment_parentpost_id.append(submission.id)\n",
    " \n",
    "    # put posts into a df\n",
    "    df_post = pd.DataFrame({'title': post_title,\n",
    "                              'id': post_id,\n",
    "                            'date_created':post_date,\n",
    "                              'text': post_text,\n",
    "                              'distinguished': post_dist,\n",
    "                              'score': post_score,\n",
    "                              'upvote_ratio': post_upvoteratio})\n",
    "    df_post['date_created'] = pd.to_datetime(df_post['date_created'], unit = 's')\n",
    "    \n",
    "    # put comments into a df\n",
    "    df_comments = pd.DataFrame({'post_id': comment_parentpost_id,\n",
    "                              'comment_text': comment_text,\n",
    "                              'comment_distinguished': comment_dist,\n",
    "                              'comment_score': comment_score})\n",
    "    \n",
    "    return df_post, df_comments\n",
    "\n",
    "\n",
    "# Putting saving the code within the loop itself to avoid accidents \n",
    "aita_posts, aita_comments = scrape_subreddit('AmiTheAsshole')\n",
    "\n",
    "aita_posts.to_csv('datasets/posts2.csv', index=False)\n",
    "aita_comments.to_csv('datasets/comments2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T06:48:49.650902Z",
     "start_time": "2021-01-24T06:09:42.737206Z"
    }
   },
   "outputs": [],
   "source": [
    "#Third Pull 7/1\n",
    "#Acessing the reddit api\n",
    "reddit = praw.Reddit(client_id=\"9tAy2O858UyM-Q\",#client id\n",
    "                     client_secret=\"wRRhIAzTIgVBvcsvJftgZfK6dC4Nsg\", #client secret\n",
    "                     user_agent=\"alex_bot\") #user agent name\n",
    "\n",
    "# define custom scraping function\n",
    "def scrape_subreddit(subreddit, postlimit=1000):\n",
    "    \n",
    "    subreddit = reddit.subreddit(subreddit)\n",
    "\n",
    "    post_title = []\n",
    "    post_text = []\n",
    "    post_id = []\n",
    "    post_dist = []\n",
    "    post_score = []\n",
    "    post_upvoteratio = []\n",
    "    post_date = []\n",
    "    comment_text = []\n",
    "    comment_dist = []\n",
    "    comment_score = []\n",
    "    comment_parentpost_id = []\n",
    "\n",
    "    # collect from posts sorted by hot\n",
    "    for submission in subreddit.hot(limit = postlimit):\n",
    "        # collect information on post\n",
    "        post_title.append(submission.title)\n",
    "        post_text.append(submission.selftext)\n",
    "        post_id.append(submission.id)\n",
    "        post_dist.append(submission.distinguished)\n",
    "        post_score.append(submission.score)\n",
    "        post_upvoteratio.append(submission.upvote_ratio)\n",
    "        post_date.append(submission.created_utc)\n",
    "\n",
    "        # collect all comments on each post\n",
    "        submission.comments.replace_more(limit = None)\n",
    "        for comment in submission.comments.list():     \n",
    "            comment_text.append(comment.body)\n",
    "            comment_dist.append(comment.distinguished)\n",
    "            comment_score.append(comment.score)\n",
    "            comment_parentpost_id.append(submission.id)\n",
    " \n",
    "    # put posts into a df\n",
    "    df_post = pd.DataFrame({'title': post_title,\n",
    "                              'id': post_id,\n",
    "                            'date_created':post_date,\n",
    "                              'text': post_text,\n",
    "                              'distinguished': post_dist,\n",
    "                              'score': post_score,\n",
    "                              'upvote_ratio': post_upvoteratio})\n",
    "    df_post['date_created'] = pd.to_datetime(df_post['date_created'], unit = 's')\n",
    "    \n",
    "    # put comments into a df\n",
    "    df_comments = pd.DataFrame({'post_id': comment_parentpost_id,\n",
    "                              'comment_text': comment_text,\n",
    "                              'comment_distinguished': comment_dist,\n",
    "                              'comment_score': comment_score})\n",
    "    \n",
    "    return df_post, df_comments\n",
    "\n",
    "\n",
    "# scrape\n",
    "aita_posts, aita_comments = scrape_subreddit('AmiTheAsshole')\n",
    "\n",
    "aita_posts.to_csv('datasets/posts3.csv', index=False)\n",
    "aita_comments.to_csv('datasets/comments3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T08:32:34.428693Z",
     "start_time": "2021-01-13T08:01:31.549470Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fourth Pull 13/1\n",
    "#Acessing the reddit api\n",
    "reddit = praw.Reddit(client_id=\"9tAy2O858UyM-Q\",#client id\n",
    "                     client_secret=\"wRRhIAzTIgVBvcsvJftgZfK6dC4Nsg\", #client secret\n",
    "                     user_agent=\"alex_bot\") #user agent name\n",
    "\n",
    "# define custom scraping function\n",
    "def scrape_subreddit(subreddit, postlimit=1000):\n",
    "    \n",
    "    subreddit = reddit.subreddit(subreddit)\n",
    "\n",
    "    post_title = []\n",
    "    post_text = []\n",
    "    post_id = []\n",
    "    post_dist = []\n",
    "    post_score = []\n",
    "    post_upvoteratio = []\n",
    "    post_date = []\n",
    "    comment_text = []\n",
    "    comment_dist = []\n",
    "    comment_score = []\n",
    "    comment_parentpost_id = []\n",
    "\n",
    "    # collect from posts sorted by hot\n",
    "    for submission in subreddit.hot(limit = postlimit):\n",
    "        # collect information on post\n",
    "        post_title.append(submission.title)\n",
    "        post_text.append(submission.selftext)\n",
    "        post_id.append(submission.id)\n",
    "        post_dist.append(submission.distinguished)\n",
    "        post_score.append(submission.score)\n",
    "        post_upvoteratio.append(submission.upvote_ratio)\n",
    "        post_date.append(submission.created_utc)\n",
    "\n",
    "        # collect all comments on each post\n",
    "        submission.comments.replace_more(limit = None)\n",
    "        for comment in submission.comments.list():     \n",
    "            comment_text.append(comment.body)\n",
    "            comment_dist.append(comment.distinguished)\n",
    "            comment_score.append(comment.score)\n",
    "            comment_parentpost_id.append(submission.id)\n",
    " \n",
    "    # put posts into a df\n",
    "    df_post = pd.DataFrame({'title': post_title,\n",
    "                              'id': post_id,\n",
    "                            'date_created':post_date,\n",
    "                              'text': post_text,\n",
    "                              'distinguished': post_dist,\n",
    "                              'score': post_score,\n",
    "                              'upvote_ratio': post_upvoteratio})\n",
    "    df_post['date_created'] = pd.to_datetime(df_post['date_created'], unit = 's')\n",
    "    \n",
    "    # put comments into a df\n",
    "    df_comments = pd.DataFrame({'post_id': comment_parentpost_id,\n",
    "                              'comment_text': comment_text,\n",
    "                              'comment_distinguished': comment_dist,\n",
    "                              'comment_score': comment_score})\n",
    "    \n",
    "    return df_post, df_comments\n",
    "\n",
    "\n",
    "# scrape\n",
    "aita_posts, aita_comments = scrape_subreddit('AmiTheAsshole')\n",
    "\n",
    "aita_posts.to_csv('datasets/posts4.csv', index=False)\n",
    "aita_comments.to_csv('datasets/comments4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:09:27.869668Z",
     "start_time": "2021-01-21T05:38:03.961184Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fourth Pull 21/1\n",
    "#Acessing the reddit api\n",
    "reddit = praw.Reddit(client_id=\"9tAy2O858UyM-Q\",#client id\n",
    "                     client_secret=\"wRRhIAzTIgVBvcsvJftgZfK6dC4Nsg\", #client secret\n",
    "                     user_agent=\"alex_bot\") #user agent name\n",
    "\n",
    "# define custom scraping function\n",
    "def scrape_subreddit(subreddit, postlimit=1000):\n",
    "    \n",
    "    subreddit = reddit.subreddit(subreddit)\n",
    "\n",
    "    post_title = []\n",
    "    post_text = []\n",
    "    post_id = []\n",
    "    post_dist = []\n",
    "    post_score = []\n",
    "    post_upvoteratio = []\n",
    "    post_date = []\n",
    "    comment_text = []\n",
    "    comment_dist = []\n",
    "    comment_score = []\n",
    "    comment_parentpost_id = []\n",
    "\n",
    "    # collect from posts sorted by hot\n",
    "    for submission in subreddit.hot(limit = postlimit):\n",
    "        # collect information on post\n",
    "        post_title.append(submission.title)\n",
    "        post_text.append(submission.selftext)\n",
    "        post_id.append(submission.id)\n",
    "        post_dist.append(submission.distinguished)\n",
    "        post_score.append(submission.score)\n",
    "        post_upvoteratio.append(submission.upvote_ratio)\n",
    "        post_date.append(submission.created_utc)\n",
    "\n",
    "        # collect all comments on each post\n",
    "        submission.comments.replace_more(limit = None)\n",
    "        for comment in submission.comments.list():     \n",
    "            comment_text.append(comment.body)\n",
    "            comment_dist.append(comment.distinguished)\n",
    "            comment_score.append(comment.score)\n",
    "            comment_parentpost_id.append(submission.id)\n",
    " \n",
    "    # put posts into a df\n",
    "    df_post = pd.DataFrame({'title': post_title,\n",
    "                              'id': post_id,\n",
    "                            'date_created':post_date,\n",
    "                              'text': post_text,\n",
    "                              'distinguished': post_dist,\n",
    "                              'score': post_score,\n",
    "                              'upvote_ratio': post_upvoteratio})\n",
    "    df_post['date_created'] = pd.to_datetime(df_post['date_created'], unit = 's')\n",
    "    \n",
    "    # put comments into a df\n",
    "    df_comments = pd.DataFrame({'post_id': comment_parentpost_id,\n",
    "                              'comment_text': comment_text,\n",
    "                              'comment_distinguished': comment_dist,\n",
    "                              'comment_score': comment_score})\n",
    "    \n",
    "    return df_post, df_comments\n",
    "\n",
    "\n",
    "# scrape\n",
    "aita_posts, aita_comments = scrape_subreddit('AmiTheAsshole')\n",
    "\n",
    "aita_posts.to_csv('datasets/posts4_1.csv', index=False)\n",
    "aita_comments.to_csv('datasets/comments4_1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
